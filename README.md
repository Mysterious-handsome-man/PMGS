# Reconstruction of Projectile Motion with 3D Gaussian Splatting  
(Clarification: In order not to violate the double-blind policy, except for the title and necessary image captions, we will not repeat any text that appears in the submitted paper on this anonymous website.)

## Teaser
![teaser_00](https://github.com/user-attachments/assets/5cf97a74-c4d1-4666-87a7-cb839b0403e9)


## Intro
<p align="center">
  <img src="https://github.com/user-attachments/assets/d437744d-d74d-4b6e-a64c-f60e1213dd12" width="50%">
</p>

(a) Dynamic-to-static conversion.  
(b) Dynamic neural rendering, which reconstructs dynamic scene with deformation field.  
(c) Our combined static-dynamic pipeline for target modeling and full-sequence motion recovery.  

## Method
#### (1) Overview:
![Methods_00](https://github.com/user-attachments/assets/437eb8e7-f798-4941-a0ba-4f07c2c90695)

#### (2) Dynamic Simulated Annealing (DSA) strategy:
<p align="center">
  <img src="https://github.com/user-attachments/assets/af0a2531-5d22-4563-9d49-b4753ab99a8f" width="50%">
</p>

## Demo
### (1) Synthetic（Left-Render; Right-GT）：

<p align="left">
  <img src="https://github.com/user-attachments/assets/74642537-f5a6-4394-aaac-134738a151b5" width="48%">
  <img src="https://github.com/user-attachments/assets/20bb5697-3745-4f13-97f9-be9e80bb7831" width="48%">
</p>

<p align="left">
  <img src="https://github.com/user-attachments/assets/bcd0f7ce-c3d2-4d6a-9001-9d986e2ee707" width="48%"> 
  <img src="https://github.com/user-attachments/assets/fdf52a20-5dd3-459d-beff-4009b1199c92" width="48%">
</p>

<p align="left">
  <img src="https://github.com/user-attachments/assets/b288ca64-47eb-4b19-bad1-1967ee51251f" width="48%">
  <img src="https://github.com/user-attachments/assets/b4816a6d-c30c-48ee-844a-74c4a9cc1f25" width="48%">
</p>

### (2) Real：
![box_full_results-ezgif com-video-to-gif-converter](https://github.com/user-attachments/assets/3f199596-4f85-47db-b5da-7a57d7a98432)

![bear_results-ezgif com-video-to-gif-converter](https://github.com/user-attachments/assets/a5348f9b-964e-4e89-9449-51ac65158574)

![sb_full_results-ezgif com-video-to-gif-converter](https://github.com/user-attachments/assets/3c615cdf-8b1a-496e-ac3f-59bc8d483377)

## Comparison of baseline
In addition to the results already presented in the paper, we have produced a video demonstrating the outcomes of COLMAP-Free GS (CFGS) to provide a more intuitive comparison.  
To validate our method's superiority in 6DoF motion estimation (achieved through the synergistic optimization of acceleration consistency prior, optical flow smoothness regularization, and dynamic simulated annealing), we conduct comparisons with CFGS under the following rigorously designed protocol:  

(1) Methodological Parallelism: CFGS adopts a comparable strategy: per-frame Gaussian field parameterization scheme for 6DoF motion estimation.  
(2) Failure Mitigation: As CFGS's monocular depth estimation module yields poor results across all our datasets (leading to 3D reconstruction failure), we deactivate this module to eliminate systematic errors, enabling pure motion recovery evaluation.  
(3) Fair Comparison: Instead, for fair comparison, we input the Gaussian fields generated by our PMGS framework into CFGS for pose estimation.  

### (1) Synthetic：

<p align="left">
  <img src="https://github.com/user-attachments/assets/4ca8474c-a473-4db8-b449-8149951ef516" width="48%">
  <img src="https://github.com/user-attachments/assets/cd21ce38-941a-438b-9281-3dade9e1a963" width="48%">
</p>

<p align="left">
  <img src="https://github.com/user-attachments/assets/12f22f08-3680-4d36-9659-cd913fc4fb24" width="48%"> 
  <img src="https://github.com/user-attachments/assets/341b330e-9bd1-4391-a512-29f0cae77e30" width="48%">
</p>

<p align="left">
  <img src="https://github.com/user-attachments/assets/04672ed2-4476-498e-99ad-b644a1822588" width="48%">
  <img src="https://github.com/user-attachments/assets/667332c7-a310-457f-a61e-672e359978ae" width="48%">
</p>

### (2) Real：

![Box-ezgif com-video-to-gif-converter](https://github.com/user-attachments/assets/bd942a0f-4e93-42a3-808e-76635b170a6a)

![Bear-ezgif com-video-to-gif-converter](https://github.com/user-attachments/assets/478f8872-21fd-42dc-b1e6-2bfcf52e850f)

![Shark-ezgif com-video-to-gif-converter (1)](https://github.com/user-attachments/assets/7a6b4532-4271-4b4d-af2e-e44c5cd2de7e)

##  Remaining experiments
### (1) Comparison of modeling:
<p align="center">
  <img src="https://github.com/user-attachments/assets/bbc8b321-6ea9-47ce-9269-349ee3ed881a" width="50%">
</p>

### (2) Complete comparison of motion recovery:
![Comparison_00](https://github.com/user-attachments/assets/9f0591ed-b7a8-436f-9af4-51277de23776)

### (3) Extensive demonstration:
![broad_00](https://github.com/user-attachments/assets/8208f348-0446-4b13-80da-c3ad66a4b819)
(a) The equivalent camera poses estimated by Mast3R exhibit noticeable incorrect disorder.  
(b) PMGS reconstructs the 3D motion of the object's centroid.  
(c) PMGS estimates the instantaneous velocity throughout the motion process.  
(d) The object's future motion trajectory can be predicted based on the centroid coordinates.  

## Ablation
<p align="center">
  <img src="https://github.com/user-attachments/assets/56ab0373-ad96-43aa-b1ec-0e22e6e9177e" width="50%">
</p>
Model 1: w/o Focus-Align modeule;   
Modle 2: w/o $L_Acc$ and $L_Smooth$;   
Modle 3: w/o DSA strategy.   

